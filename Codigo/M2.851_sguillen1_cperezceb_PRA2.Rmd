---
title: 'PRA2'
date: " "
output:
  pdf_document:
    highlight: zenburn
    toc: yes
  html_document:
    highlight: default
    number_sections: no
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: M2.851_Header.html
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=T, echo=T)
```

Requeriremos de los paquetes ggplot2, gridExtra y grid de R. 

```{r echo=FALSE, message= FALSE, warning=FALSE}

if(!require(ggplot2)){
    install.packages('ggplot2', repos='http://cran.us.r-project.org')
    library(ggplot2)
}

if(!require(grid)){
    install.packages('grid', repos='http://cran.us.r-project.org')
    library(grid)
}
if(!require(gridExtra)){
    install.packages('gridExtra', repos='http://cran.us.r-project.org')
    library(gridExtra)
}

if(!require(dplyr)){
    install.packages('dplyr', repos='http://cran.us.r-project.org')
    library(dplyr)
}

if(!require(ggthemes)){
    install.packages('ggthemes', repos='http://cran.us.r-project.org')
    library(ggthemes)
}
if(!require(scales)){
    install.packages('scales', repos='http://cran.us.r-project.org')
    library(scales)
}
if(!require(GGally)){
    install.packages('GGally', repos='http://cran.us.r-project.org')
    library(GGally)
}
if(!require(kableExtra)){
    install.packages('kableExtra', repos='http://cran.us.r-project.org')
    library(kableExtra)
}
if(!require(randomForest)){
    install.packages('randomForest', repos='http://cran.us.r-project.org')
    library(randomForest)
}
```

******
# Descripción del dataset
******

Para el desarrollo de esta práctica se ha optado por la elección del dataset: "Titanic: Machine Learning from Disaster (https://www.kaggle.com/c/titanic)". Este dataset contiene información de uno de los naufragios más conocido de la historia, donde se tienen datos relativos a sus pasajeros como edad, sexo, clase en que viajaban, ... Este dataset es muy utilizado para el entrenamiento de algoritmos, y actualmente forma parte de una competición de Kaggle. 


A partir del análisis de este dataset, se pretende averiguar si existe alguna variable que influya en la supervivencia o no.Así como conocer qué tipo de personas en bases a sus características físicas y las de su viaje tenían más probabilidades se sobrevivir.

La actividad se centra en el tratamiento de un dataset. En primer lugar, tendremos una fase de estudio previo para conocer cómo son nuestros datos, su estructura y su comportamiento. Una segunda fase de preparación, dónde aplicaremos la técnicas necesarias para la adecuación de los datos para la siguiente fase de análisis y, finalmente, y extraeremos conclusiones.


Disponemos de tres conjuntos de datos que se describen a continuación:


* train.csv: Es el que debe usarse para construir los modelos de aprendizare automático. Se porporciona el resultado de la variable _Survived_ que incida la superivivencia de cada pasajero que es sobre la que se va a llevar a cabo la práctica. Contiene un total de 891 observaciones.

* test.csv: Se compone de un total de 418 observaciones  y es el que debe usarse para ver la precisión del modelo generado con el dataset anterior. No se proporciona la variable _Survived_.

* gender_submission.csv: Es el que contiene los valores de la variable _Survived_ para cada pasajero.


Disponemos de un total de 1309 muestras y 12 variables distintas; 5 de tipo carácter, 5 de tipo integer y 2 numéricas. A continuación, se va a llevar a cabo la descripción de los atributos que forman parte del dataset:


+ **PassengerId**: Identificador del pasajero o tripulante.

+ **Survived**: Indica si el pasajero o tripulante ha sobrevivido. El valor _0_ indica que no ha sobrevivido y el _1_ que sí. Es la variable que se trata de predecir en el conjunto de test.

+ **Pclass**: Es la clase en la que ha navegado el pasajero. Existen los siguientes valores: _1_ es primera clase, _2_ es segunda clase y _3_ es tercera clase.

+ **Name**: Nombre completo del pasajero.

+ **Sex**: Género del pasajerondividuo. Existen los siguientes Valores: _male_ para hombre y _female_ para mujer.

+ **Age**: Edad en años del pasajero.

+ **SibSp**: Número de hermanos o cónyuges a bordo del barco.

+ **Parch**: Número de padres o hijos a bordo del barco.

+ **Ticket**: El indentificador del ticket. Todos los miembros de una familia tendrán el mismo identificador de ticket, un único billete.

+ **Fare**: Tarifa del billete.

+ **Cabin**: Número de cabina.

+ **Embarked**: Puerto en el que ha embarcado el pasajero. Exiten los siguientes valores: _C_ corresponde a Cherbourg, _Q_ corresponde a Queenstown y _S_ corresponde a Southampton.


******
# Integración y selección de los datos de interés a analizar.
******

# Lectura del dataset

En este aparatado se va a llevar acabo la integración y la selección de los datos que van a ser de interés para llevar a cabo el análisis.

Como se ha comentado en el apartado anterior, hay tres conjunto de datos. Cada conjunto tiene un identificador único que es la variable _PassengerId_ que permite relacionar 

```{r}
# Carga de los diferentes datasets

dataTrain<-read.csv("./data/train.csv",header=T,sep=",")
dataTest <-read.csv("./data/test.csv",header=T,sep=",")
dataReferencias <-read.csv("./data/gender_submission.csv",header=T,sep=",")


# Unimos los tres dataset en uno

dataTest <- merge(dataTest, dataReferencias, by="PassengerId")

data <- rbind(dataTrain, dataTest)

```

Una vez se ha unificado los datos, se inspeccionará el conjuntos de datos: 

```{r}
# Observamos la estructura de los datos

str(data)

```

```{r}
summary(data)
```


******
# Limpieza de los datos.
******

## Varible _Name_

En primer lugar analizaremos la variables _Name_:

```{r}
data$Title <- gsub('(.*, )|(\\..*)', '', data$Name)
rare_title <- c('Dona', 'Lady', 'the Countess','Capt', 'Col', 'Don',
'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer')
data$Title[data$Title == 'Mlle'] <- 'Miss'
data$Title[data$Title == 'Ms'] <- 'Miss'
data$Title[data$Title == 'Mme'] <- 'Mrs'
data$Title[data$Title %in% rare_title] <- 'Rare Title'
data$Title <- as.factor(data$Title)
data$Surname <- sapply(data$Name,
function(x) strsplit(x, split = '[,.]')[[1]][1])

data$Surname <- as.factor(data$Surname)
```


## Variable _SibSp_ y _Parch_

En este apartado se combinarán la variables _SibSp_ y _Parch_ para crear una nueva variables llamada _Famsize_.

```{r}

data$Famsize <- data$SibSp + data$Parch + 1
```


```{r}

data$Fsize[data$Famsize == 1] <- 'singleton'
data$Fsize[data$Famsize < 5 & data$Famsize > 1] <- 'small'
data$Fsize[data$Famsize > 4] <- 'large'

data$Fsize <- as.factor(data$Fsize)


mosaicplot(table(data$Famsize, data$Survived), main='Family Size by Survival', shade=TRUE)
```



## Variable _Survived_


En primer lugar se convertirán a factores las variables _Survived_, _PClass_, _Sex_ y _Embarked_.

```{r}

data$Survived <- as.factor(data$Survived)

```


## Variable _PClass_

```{r}
data$Pclass <- as.factor(data$Pclass)

```


## Variable _Sex_

```{r}

data$Sex <- as.factor(data$Sex)

```

## Variable _Embarked_

```{r}

data$Embarked <- as.factor(data$Embarked)

```

## Variable _PrecioTicket_

Creamos una nueva variable con el precio medio pagado por cada pasajero. Se calcula en función del identificador del ticket y el número de personas asociadas a dicho ticket

```{r}
data <- data %>% 
          group_by(Ticket) %>% 
          mutate(PrecioTicket = Fare/n())
```


# Selección de datos

En el siguiente paso se eliminaran aquellas columnas que no contengan información útil para el desarrollo de esta práctica.

```{r}
# Eliminamos las columnas

data <- subset(data, select = -c(PassengerId, Ticket, Cabin))

```


# Valores vacios y outliers

En este apartado se analizará si las variables contienen valores nulos o incompletos.

```{r}
col_mis <- colSums(is.na(data) | data=="")
print(col_mis)

```

A continuación se trataran las variables con valores nulos o incompletos de las diferetnes variables.


## Varible _Fare_

Antes de imputar los valores perdidos de la varible _Fare_ se comprobará las características de estos valores.

```{r}

miss_fare_index <- which(is.na(data$Fare))
miss_fare <- data[miss_fare_index,]
miss_fare

```

Se visualiza los valores de la variable _Fare_ para los otros pasajeros que comparten los mismo valores para las variables _PClass_ y _Embarked_. 


```{r}

ggplot(data[data$Pclass == '3' & data$Embarked == 'S',],
       aes(x = Fare)) +
  geom_density(fill = '#99d6ff', alpha=0.4) +
  geom_vline(aes(xintercept=median(Fare, na.rm=T)),
             colour='red', linetype='dashed', lwd=1) +
  scale_x_continuous(labels=dollar_format()) +
  theme_few()
```

Después de visualizar las gráfica anterior se puede dar por válido el reemplazar el valor perdido de la variable _Fare_  por la mediana de su clase y embarque.

```{r}
data$Fare[1044] <- median(data[data$Pclass == '3' & data$Embarked == 'S', ]$Fare, na.rm = TRUE)

```

## variable _Embarked_

Antes de imputar los valores perdidos de la variable _Embarked_ se comprobará las características de estos valores.

```{r}

miss_embark_index <- which(is.na(data$Embarked))
miss_embark <- data[miss_embark_index,]
miss_embark

```

Se visualiza los valores de la variable _Fare_ para los otros pasajeros que comparten los mismo valores para las variables _PClass_ y _Fare_.

```{r}


ggplot(data[!is.na(data$Embarked),], aes(x = Embarked, y = Fare, fill = factor(Pclass))) +
  geom_boxplot() +
  geom_hline(aes(yintercept=80),
             colour='red', linetype='dashed', lwd=2) +
  scale_y_continuous(labels=dollar_format()) +
  theme_few()
```

Después de visualizar las gráfica anterior se puede dar por válido el reemplazar el valor perdido de la variable _Embarked_  por el valor _C_.

```{r}

data$Embarked[miss_embark_index] <- 'C'

```

## Variable _Age_

La variable _Age_ contiene un porcentaje mayor de valores nulos. En este caso, vamos a aplicar la imputación por vecinos más cercanos, usando la distancia Gower, considerando en el cómputo de los vecinos más cercanos el resto de variables cuantitativas. Utilizaremos la función *K-Nearest Neighbour Imputation* de la librería  *VIM* con un número de vecinos igual a 11.

```{r}
 table(is.na(data$Age))

if (!require('VIM')){
  install.packages('VIM')
  library(VIM, warn.conflicts = FALSE)
} 

data<-kNN(
  data,
  variable = "Age",
  k = 11,
  dist_var = c("Pclass","Embarked","Fare"),
  catFun = group_by(Sex),
  imp_var = FALSE
)

#Verificamos que ya no existan valores nulos
 table(is.na(data$Age))
 
```

Aprovechamos para crear una variable que identifique a los pasajeros por rango de edad

```{r}
 data["RangoEdad"] <- cut(data$Age, breaks = c(0,20,40,60,80,100), labels = c("0-19", "20-39","40-59","60-79",">79"))
str(data)
table(data$RangoEdad)
```
 
# Valores extremos

En este apartado se analizarán los valores extremos de las variables _Age_, _Fare_, _SibSp_, _Parch_ y _Fsize_.

## Variable _Age_

```{r}
boxplot(data$Age, main="Box plot", col="#FF6600")

```

```{r}
boxplot.stats(data$Age)$out
```

Se puede observar que los valores extremos están en un rango normal, ningún pasajero es menor que 0 o mayor que 100.

## Variable _Fare_

```{r}

boxplot(data$Fare, main="Box plot", col="#FF6600")
```

```{r}
boxplot.stats(data$Fare)$out
```

Evidentemente, esta gráfica no es representativa cuando el establecimiento de la tarifa depende de  muchas otras variables como puede ser la clase o el puerto de origen. Además, el precio del ticket la tarifa expuesta engloba incluye al total de  

Por lo tanto, repetimos la representación en función de la clase.

```{r}

ggplot(data, aes(x = Pclass, y = Fare)) +
  geom_boxplot() +
  geom_hline(aes(yintercept=80),
             colour='red', linetype='dashed', lwd=2) +
  scale_y_continuous(labels=dollar_format()) +
  theme_few()

```

Se puede observar que los valores extremos pertenecen a una clase específica, mientras mayor es la clase y mayor es el número de pasajeros, más alta es la tarifa.

## Variable _Famsize_

```{r}

boxplot(data$Famsize, main="Box plot", col="#FF6600")
```

```{r}
boxplot.stats(data$Famsize)$out
```

Se observar que los valores extremos están un rango normal. Por ejemplo, ninguno es menor que cero o mayor que 12. Por tanto, son valores que perfectamente pueden darse.

# Exportación de los datos

Se vuelven a revisar los datos para comprobar que no contienen valores nulos y/o vacios.

```{r}
summary(data)
```


Una vez revisado nuestro conjunto de datos hacemos una selección de las variables que queremos analizar con mayor profundidad.

El estado actual del dataset es:

```{r echo=FALSE}
str(data)
head(data)
```

De todo el conjunto de datos vamos a seleccionar las variables: 

* Survived
* Pclass
* Sex
* Age
* Fare
* Embarked
* Fsize

```{r}
# Seleccion de caracteristicas de interes

#clean_data <- select(data, -Name, -Famsize)
clean_data <- data %>%
                    select(c('Survived','Pclass', 'Sex', 'Age', 'Embarked', 'Famsize', 'Fsize', 'Fare') )
# Visualizamos los datos limpios:
summary(clean_data)
```

Se divide el dataset en dos conjuntos: train y test.

```{r}
#Dividimos el conjunto de datos en datos de entrenamiento y datos prueba.
clean_train_data <- clean_data[1:nrow(dataTrain),]
clean_test_data <- clean_data[(nrow(dataTrain) + 1):nrow(data),]


# Exportación de los datos limpios en .csv

write.csv(clean_train_data, 'clean_train.csv')
write.csv(clean_test_data, 'clean_test.csv')
          
write.csv(clean_data, 'clean_full.csv')
```


******
# Análisis de los datos
******

# Selección de los datos a comparar

De las características del conjunto de entrenamiento nos interesa analizar las variables cuantitativas Age
y Fare;y las variables cuantitativas Sex, Pclass y FSize.

Para analizar estas variables emplearemos diagramas de histogramas para las variables cuantitativas y
diagramas de barras para las variables cualitativas en función de la supervivencia.

# Relaciones de las variables independientes respecto la variable *Survived*

## Comparativa entre las variables Sex y Survived


```{r, fig.width=12, fig.height=5}

ggplot(clean_train_data,aes(Sex,fill=Survived))+geom_bar() +labs(x="Género", y="Pasajeros")+ guides(fill=guide_legend(title=""))+ scale_fill_manual(values=c("#003333","#009999"))+ggtitle("Superviviente por género")

```

Tabla de contigencia

```{r}
tablaSex <- table(clean_train_data$Sex, clean_train_data$Survived)
tablaSex
prop.table(tablaSex, margin = 1)
```


El diagrama de barras anterior muestra la distribución de supervivencia de mujeres y hombres. Como se
intuía está característica parece influir en la supervivencia. El gráfico de barras muestra que un 74% de los
pasajeros mujeres sobrevivieron, mientras que solo un 19% de los pasajeros varones sobrevivieron.
De tal forma que aquellos pasajeros con sexo femenino tuvieron una tasa de supervivencia más alta que los
varones.


## Comparativa entre las variables Pclass y Survived

```{r}

ggplot(clean_train_data, aes(x = Pclass, fill = Survived)) + 
  geom_bar(stat='count', position='dodge') +
  labs(x = 'Clase') +
  ggtitle("Superviviente por clase") +
  theme_few()
```

```{r}
tablaClass <- table(clean_train_data$Pclass, clean_train_data$Survived)
tablaClass
prop.table(tablaClass, margin = 1)
```

Las gráficas anteriores muestran la distribución de la supervivencia en función de la clase del pasajero. En el gráfico se observa que esta característica parece influir en la supervivencia. El gráfico de barras muestra que sobre el 63 % de los pasajeros de primera clase sobrevivieron, mientras que sobre el 48 % de los pasajeros de segunda clase sobrevivieron, y solo el 24 % de los pasajeros de tercera clase sobrevivieron.
De tal forma que aquellos pasajeros en las clases más altas tienen una tasa de supervivencia más alta que aquellos pasajeros en las clases más bajas.



## Comparativa entre las variables Embarked y Survived

```{r}
ggplot(clean_train_data, aes(x = Embarked, fill = Survived)) +
  geom_bar(stat='count', position='dodge') +
  labs(x = 'Embarked') +
  theme_few()
```

## Comparativa entre las variables Fsize y Survived

```{r}
ggplot(clean_train_data, aes(x = Fsize, fill = Survived)) +
  geom_bar(stat='count', position='dodge') +
  labs(x = 'Family size') +
  theme_few()
```

La gráfica anterior muestra que sobre el 70% los pasajeros solteros y sobre el 82% de las familias grandes no sobrevivieron. Respecto al conjunto de solteros suponemos que la mayoría deberían ser varones dado que en la época del accidente sería más habitual que estos viajen solos. Además, suponemos que las familias grandes no cabrían todos en un bote de salvavidas y esto podría influir en su supervivencia.

Más adelante analizaremos esta característica en función del sexo ya que ser soltero y varón debería ser un rasgo que influya en la supervivencia.

## Comparativa entre las variables Age y Survived

```{r}
ggplot(clean_train_data, aes(x = Age, fill = Survived)) +
  geom_histogram() +
  labs(x = 'Family size') +
  theme_few()
```

No hay nada fuera de lo común en esta trama, excepto la parte izquierda de la distribución. Demuestra que los niños y los bebés eran la prioridad, por lo tanto, se salvó una buena parte de los niños.

## Comparativa entre las variables Fare y Survived

```{r}
ggplot(clean_train_data, aes(x = Fare, fill = Survived)) +
  geom_histogram() +
  labs(x = 'Fare') +
  theme_few()
```

La gráfica anterior muestra algo interesante, existe un pico en los valores de menos de 100 dólares que representa que muchos de los pasajeros que compraron un ticket dentro de ese rango no sobrevivieron. Cuando la tarifa es aproximadamente más de 280 dólares, la tasa de mortalidad es baja, lo que significa que todos los que pasaron de esa la tarifa sobrevivieron.


# Relaciones de dos variables independientes con la variable dependiente


## Comparativa de las variables Sex y Pclass con la variable Survived

```{r}
ggplot(clean_train_data, aes(Pclass, fill = factor(Survived))) +
geom_bar(position=position_dodge()) +
facet_grid(.~Sex) +
theme_few()
```

La gráfica anterior muestra que los pasajeros mujeres y de una clase alta sobrevivieron en su mayoría. También se observa que los pasajeros varones tuvieron una tasa de supervivencia mucho más baja que las mujeres. Esta tasa de supervivencia va empeorando a medida que la clase del pasajero baje. Se puede concluir que ser de sexo y la clase pueden influir en la supervivencia del pasajero.


## Comparativa de las variables Sex y Fsize con la variable Survived

```{r}
ggplot(clean_train_data, aes(Fsize, fill = factor(Survived))) +
geom_bar(position=position_dodge()) +
labs(fill = "Survived") +
facet_grid(.~Sex) +
theme_few()
```

La gráfica anterior muestra que los pasajeros solteros varones tuvieron una tasa de mortalidad más alta. Esta valor es lógico debido que en los botes salvavidas tendrían una preferencia menor a las mujeres y niños.


## Comparativa de las variables Sex y Embarked con la variable Survived

```{r}
ggplot(clean_train_data, aes(Embarked, fill = factor(Survived))) +
geom_bar(position=position_dodge()) +
facet_grid(.~Sex) +
theme_few()
```
La gráfica anterior muestra que la mayoría de los pasajeros parece ser que embarcaron en Southampton (S). Aunque la mayoría de los pasajeros embarco en Southampton (S) a priori no debería ser relevante para la supervivencia, a menos que tenga alguna relación con la localización del camarote o la clase del pasajero.

## Comparativa de las variables Sex y Age con la variable Survived

```{r}
ggplot(clean_train_data, aes(x = Age, fill = factor(Survived))) +
geom_histogram() +
facet_grid(.~Sex) +
theme_few()
```

La gráfica anterior muestra que la supervivencia de los varones es baja para los adultos. Los niños varones tienen una tasa de supervivencia alta, esto es lógico debido a la preferencia que tuvieron estos en los botes. Por tanto, podemos concluir que el sexo y la edad de los pasajeros son características que influyen en la supervivencia.

## Comparativa de las variables Sex y Fare con la variable Survived

```{r}
ggplot(clean_train_data, aes(x = Fare, fill = factor(Survived))) +
geom_histogram() +
facet_grid(.~Sex) +
theme_few()
```

La gráfica anterior no se observa algo nuevo. Solamente que la condición socioeconómica parece un factor que puede influir en la supervivencia. De las gráficas anteriores se concluye que las características Age,Sex, Fare y Pclass parecen tener influyen en la supervivencia.


# Comprobación de la normalidad y homogeneidad de la varianza

## Normalidad

En este apartado se revisará si las variables siguen una distribución normal.

```{r}
alpha = 0.05
drawQQPlotAndtHist <- function(dataset) {
  par(mfrow=c(2,2))
  for(i in 1:ncol(dataset)) {
    if (is.numeric(dataset[,i])){
      qqnorm(dataset[,i],main = paste("Normal Q-Q Plot for ",colnames(dataset)[i]))
      qqline(dataset[,i],col="red")
      hist(dataset[,i],
           main=paste("Histogram for ", colnames(dataset)[i]),
          xlab=colnames(dataset)[i], freq = FALSE)
    }
  }
}
#Mostramos las gráficas.

drawQQPlotAndtHist(clean_train_data)
```

De las gráficas anteriores, se observa que la característica Age pueden ser candidata a la normalización. No obstante, se aplicará el test de Shapiro-Wilk para contrastar esta asunción.

**Test Shapiro-Wilk**

El test de Shapiro-Wilk se usa para contrastar si un conjunto de datos siguen una distribución normal o no. En nuestro caso se aplicará este test cada una las variables cuantitativas consideradas.
De tal forma que la hipótesis nula (H0) y la alternativa (H1) se pueden escribir de la siguiente forma:

  * Hipótesis nula (Ho): Los datos de la muestra no son significativamente diferentes de una población     normal.
  
  * Hipótesis alternativa (H1): Los datos de la muestra son significativamente diferentes de una          población normal.
  
  * Zona de rechazo. Para todo valor de probabilidad mayor que un nivel de significación p = 0.05, se     acepta Ho y se rechaza H1.

Para comprobar la asunción de normalidad aplicamos el test Shapiro-Wilk, para ello utilizamos la función **shapiro.test**. A continuación, se muestra la aplicación del test Shapiro-Wilk para las variables cuantitativas consideradas:

```{r}
shapiro.test(clean_train_data$Age)
```

```{r}
shapiro.test(clean_train_data$Famsize)
```

```{r}
shapiro.test(clean_train_data$Fare)
```
Dado los resultados anteriores, se observa que para las cuatro características consideradas sus correspondientes p-valores son inferiores al nivel de significación (p = 0.05). Por tanto, rechazamos la H0 y concluimos con un 95% de confianza que los datos no se distribuyen normalmente.


A continuación se aplicará este test para realizar el contraste de si existen diferencias en la edad (Age) en función de la supervivencia (Survived).

```{r}
age_sur_0 <- clean_train_data$Age[clean_train_data$Survived==0]
age_sur_1 <- clean_train_data$Age[clean_train_data$Survived==1]

par(mfrow=c(1,2))
qqnorm(age_sur_0, main = paste("Normal Q-Q Plot for ", colnames(age_sur_0)[1]))
qqline(age_sur_0, col="red")
hist(age_sur_0,
main=paste("Histogram for ", colnames(age_sur_0)[1]),
xlab=colnames(age_sur_0)[1], freq = FALSE)


```
```{r}
par(mfrow=c(1,2))
qqnorm(age_sur_1, main = paste("Normal Q-Q Plot for ", colnames(age_sur_1)[1]))
qqline(age_sur_1, col="red")
hist(age_sur_1,
     main=paste("Histogram for ", colnames(age_sur_1)[1]),
xlab=colnames(age_sur_1)[1], freq = FALSE)
```
```{r}
shapiro.test(age_sur_0)
```


```{r}
shapiro.test(age_sur_1)
```
Dado los resultados anteriores, se observa que para las cuatro características consideradas sus correspondientes p-valores son inferiores al nivel de significación (p = 0.05). Por tanto, rechazamos la H0 y concluimos con un 95% de confianza que los datos no se distribuyen normalmente.

A continuación se aplicará este test para realizar el contraste de si existen diferencias en la característica familiares a bordo (SibSp) en función de la supervivencia (Survived).

```{r}
Famsize_sur_0 <- clean_train_data$Famsize[clean_train_data$Survived==0]
Famsize_sur_1 <- clean_train_data$Famsize[clean_train_data$Survived==1]

par(mfrow=c(1,2))
qqnorm(Famsize_sur_0, main = paste("Normal Q-Q Plot for ", colnames(Famsize_sur_0)[1]))
qqline(Famsize_sur_0, col="red")
hist(Famsize_sur_0,
     main=paste("Histogram for ", colnames(Famsize_sur_0)[1]),
xlab=colnames(Famsize_sur_0)[1], freq = FALSE)
```

```{r}
par(mfrow=c(1,2))
qqnorm(Famsize_sur_1, main = paste("Normal Q-Q Plot for ", colnames(Famsize_sur_1)[1]))
qqline(Famsize_sur_1, col="red")
hist(Famsize_sur_1,
main=paste("Histogram for ", colnames(Famsize_sur_1)[1]),
xlab=colnames(Famsize_sur_1)[1], freq = FALSE)
```

```{r}
shapiro.test(Famsize_sur_0)
```

```{r}
shapiro.test(Famsize_sur_1)
```

Dado los resultados anteriores, se observa que para las cuatro características consideradas sus correspondientes valores son inferiores al nivel de significación (p = 0.05). Por tanto, rechazamos la H0 y concluimos con un 95% de confianza que los datos no se distribuyen normalmente.

Ahora se aplicará este test para realizar el contraste de si existen diferencias en la característica Tarifa (Fare) en función de la supervivencia (Survived).

```{r}
Fare_sur_0 <- clean_train_data$Fare[clean_train_data$Survived==0]
Fare_sur_1 <- clean_train_data$Fare[clean_train_data$Survived==1]

par(mfrow=c(1,2))
qqnorm(Fare_sur_0, main = paste("Normal Q-Q Plot for ", colnames(Fare_sur_0)[1]))
qqline(Fare_sur_0, col="red")
hist(Fare_sur_0,
main=paste("Histogram for ", colnames(Fare_sur_0)[1]),
xlab=colnames(Fare_sur_0)[1], freq = FALSE)
```

```{r}
par(mfrow=c(1,2))
qqnorm(Fare_sur_1, main = paste("Normal Q-Q Plot for ", colnames(Fare_sur_1)[1]))
qqline(Fare_sur_1, col="red")
hist(Fare_sur_1,
main=paste("Histogram for ", colnames(Fare_sur_1)[1]),
xlab=colnames(Fare_sur_1)[1], freq = FALSE)
```

```{r}
shapiro.test(Fare_sur_0)
```

```{r}
shapiro.test(Fare_sur_1)
```

Dado los resultados anteriores, se observa que para las cuatro características consideradas sus correspondientes p-valores son inferiores al nivel de significación (p = 0.05). Por tanto, rechazamos la H0 y concluimos con un 95% de confianza que los datos no se distribuyen normalmente.


## Homegeneidad de la varianza

En este apartado se estudiará la homegeneidad de la varianza utilizando el test de Filgener-killeen. Se trata de un test no paramétrico que compara las varianzas basándose en la mediana. Es una alternativa cuando no se cumple la condición de normalidad en las muestras. De tal forma que la hipótesis nula (H0) y la alternativa (H1) se pueden escribir de la siguiente forma: 

  * Hipótesis nula (Ho): Todas las varianzas de las poblaciones son iguales.
  
  * Hipótesis alternativa (H1): Al menos dos de ellos difieren.
  
  * Zona de rechazo. Para todo valor de probabilidad mayor que un nivel de significación  = 0.05, se     acepta Ho y se rechaza H1.

Para realizar el test Fligner-Killeen se utiliza la función fligner.test(). A continuación, se muestra la aplicación del test Fligner-Killeen para la característica cuantitativas Edad (Age) en función de la Supervivencia (Survived):

```{r}
boxplot(Age ~ Survived, data = clean_train_data)
```

```{r}
fligner.test(Age ~ Survived, data = clean_train_data)
```
Puesto que obtenemos un p-valor superior al nivel de significación (p = 0.05), aceptamos la hipótesis nula (H0), es decir, de que las varianzas de ambas muestras son homogéneas.

A continuación, se muestra la aplicación del test Fligner-Killeen para característica familiares a bordo (Famsize) en función de la Supervivencia (Survived):

```{r}
fligner.test(Famsize ~ Survived, data = clean_train_data)
```
Puesto que obtenemos un p-valor superior al nivel de significación (p = 0.05), aceptamos la hipótesis nula (H0), es decir, de que las varianzas de ambas muestras son homogéneas.


A continuación, se muestra la aplicación del test Fligner-Killeen para la característica Tarifa (Fare) en función de la Supervivencia (Survived):

```{r}
fligner.test(Fare ~ Survived, data = clean_train_data)
```
Puesto que obtenemos un p-valor inferior al nivel de significación (p = 0.05), rechazamos la hipótesis nula (H0), y podemos concluir que las varianzas son significativamente diferentes.


# Apliación de pruebas estadísticas para comparar los grupos de datos.


## Contraste de hipótesis

En este apartado se aplicará un contraste de hipótesis sobre dos muestras para determinar si la supervivencia dependiendo de otra variable categórica. Para comparar la dependencia entre dos variables categóricas se utilizará la prueba de chi-cuadrado. El contraste de hipótesis a realizar se expresa así:

  * Hipótesis nula (Ho). Los dos factores son independientes.
  
  * Hipótesis alternativa (H1): Los dos factores son dependentes.
  
  * Zona de rechazo. Para todo valor de probabilidad mayor que un nivel de significación p = 0.05, se     acepta Ho y se rechaza H1.

Una vez establecido las hipótesis para cada conjunto de variables categóricas consideradas se construirá su correspondiente tabla de contingencia y se aplicará el test chi-cuadrado, para ello se empleará la función chisq.test().

A continuación, se calculan la prueba chi-cuadrado para varios pares de variables categóricas.

### Variables Survived-Sex

```{r}
tbl = table(clean_train_data$Survived, clean_train_data$Sex)
tbl
```
Aplicamos la función chisq.test a la tabla de contingencia tbl:

```{r}
chisq.test(tbl)
```

Como el valor de p-valor es menor que el nivel de significancia de 0.05, por tanto rechazamos la hipótesis nula (H0) y aceptamos la hipótesis alternativa. Por tanto, concluimos que la supervivenvia depende del sexo del pasajero (Sex)

### Variables Survived-Pclass

```{r}
tbl = table(clean_train_data$Survived, clean_train_data$Pclass)
tbl
```

Aplicamos la función chisq.test a la tabla de contingencia tbl:

```{r}
chisq.test(tbl)
```
Como el valor de p-valor es menor que el nivel de significancia de 0.05, por tanto rechazamos la hipótesis nula (H0) y aceptamos la hipótesis alternativa. Por tanto, concluimos que la supervivenvia depende la clase del pasajero (Pclass).


### Variables Survived-Fsize

```{r}
tbl = table(clean_train_data$Survived, clean_train_data$Fsize)
tbl
```
Aplicamos la función chisq.test a la tabla de contingencia tbl:

```{r}
chisq.test(tbl)
```
Como el valor de p-valor es menor que el nivel de significancia de 0.05, por tanto rechazamos la hipótesis nula (H0) y aceptamos la hipótesis alternativa. Por tanto, concluimos que la supervivenvia depende del tamaño de la familia (Fsize)


## Corelación

En este apartado procedemos a realizar un análisis de correlación entre las distintas variables numéricas del conjunto de datos. Cuando dos características o más tienen correlación, eso significa que se están explicando unas a otras al tiempo con lo que proporcionan solo poca o ninguna información nueva.

```{r}
# Calculamos las correlaciones.
corr_data <- select_if(clean_train_data, is.numeric)

corr.res <- cor(corr_data)
# Mostramos las gráficas
ggpairs(corr_data)
```


La gráfica anterior muestra que existe una correlación positiva entre las variables Parch y SibSp. Esto tiene sentido debido a que ambas variables hacen referencia al tamaño de la familia que va a bordo.

## Regresión Logística

La estrategia por seguir será partir de un modelo donde la supervivencia dependa de la Edad (Age), la tarifa (Fare), el tamaño de la familia a bordo (Fsize), la embarcación (Embarked), el sexo (Sex) y la clase (Pclass). Partiendo de esta modelo ser irá añadiendo y quitando variables con el propósito de mejorar el modelo.
En primer lugar, establecemos categorías de referencia para las variables cualitativas: “F” para la variable Sex, “S” para la variable Embarked, “1” para la variable Pclass, “small” para la variable Fsize; para ello utilizamos la función relevel().

```{r}
# Nivel de significancia

sig_level = 0.05

# Establecemos categoria de referencia conjunto de datos.

clean_train_data$SexR <- relevel(clean_train_data$Sex, ref="female")
clean_train_data$EmbarkedR <- relevel(clean_train_data$Embarked, ref="S")
clean_train_data$PclassR <- relevel(clean_train_data$Pclass, ref="1")
clean_train_data$FsizeD <- relevel(clean_train_data$Fsize, ref="small")

# Establecemos categoria de referencia conjunto de pruebas

clean_test_data$SexR <- relevel(clean_test_data$Sex, ref="female")
clean_test_data$EmbarkedR <- relevel(clean_test_data$Embarked, ref="S")
clean_test_data$PclassR <- relevel(clean_test_data$Pclass, ref="1")
clean_test_data$Fsize <- relevel(clean_test_data$Fsize, ref="small")

```


Calculamos la supervivencia en función de las carácteristicas:

  • Modelo 1. Survived = Age + SibSp + Parch + Fare + EmbarkedR + SexR + PclassR.
  
  • Modelo 2. Survived = Age + SibSp + Parch + Fare + EmbarkedR + SexR + PclassR + Fsize.
  
  • Modelo 3. Survived = Age + Fare + SexR + PclassR + Fsize.
  
  • Modelo 4. Survived = Age + SexR + PclassR + Fsize.


```{r}

# Calculamos modelo 1
glm1.fit <- glm(factor(Survived) ~ Age + Fare +
                  EmbarkedR + SexR + PclassR,
                data = clean_train_data,
                family = "binomial")

glm1.summary <- summary(glm1.fit)



# Calculamos modelo 2
glm2.fit <- glm(factor(Survived) ~ Age + Fare +
                  EmbarkedR + SexR + PclassR +
                  Fsize,
                data = clean_train_data,
                family = "binomial")

glm2.summary <- summary(glm2.fit)


# Calculamos modelo 3

glm3.fit <- glm(factor(Survived) ~ Age + Fare +
                  SexR + PclassR +
                  Fsize,
                data = clean_train_data,
                family = "binomial")

glm3.summary <- summary(glm3.fit)


# Calculamos modelo 4

glm4.fit <- glm(factor(Survived) ~ Age +
                  SexR + PclassR +
                  Fsize,
                data = clean_train_data,
                family = "binomial")

glm4.summary <- summary(glm4.fit)

```


Para los anteriores modelos de regresión logística obtenidos, la bondad del modelo se evaluará mediante la medida AIC. Dado que esta medida tiene en cuenta tanto la bondad del ajuste como la complejidad del modelo, cuando se comparen varios modelos candidatos, se seleccionará aquel que resulte en el menor AIC. Para obtener los AIC’s de los modelos se utiliza la función AIC().

```{r}
aui_data <- AIC(glm1.fit, glm2.fit, glm3.fit, glm4.fit)
kable(aui_data) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
```

Dado los resultados anteriores se llega a la conclusión que se obtiene el mejor resultado con el modelo regresor 1 con un valor de 813.49.

```{r}
glm1.summary
```
```{r}
glm1.coef <- coef(glm1.fit)
glm1.coef_exp <- exp(coef(glm1.fit))
data <- data.frame(Coeficiente = glm1.coef, Exp = glm1.coef_exp)
kable(data) %>%
kable_styling(bootstrap_options = "striped", full_width = F)
```

Del modelo anterior podemos concluir que:

  • Para las variables Age, SexRMale,  PclassR2 y PclassR3, sus correspondientes p-valores son menores que 0.05, es decir, son significativas para el modelo.
  
  • El resto de variables tienen p-valores son mayores que 0.05, no son significativas y se pueden eliminar del modelo.


## Random forest


El RF es un método de clasificación basado en la realización de múltiples árboles de decisión sobre muestras de un conjunto de datos Además, Random Forest permite obtener medidas acerca de la importancia que los diferentes predictores han tenido en el modelo, lo que permite en parte interpretar este. La importancia de los predictores se evalúa como el número de veces que han sido utilizados por los diversos árboles y su capacidad para reducir el índice de Gini en ellos.

```{r}
#Set a random seed
set.seed(754)

# Build the model
rf_model <- randomForest(factor(Survived) ~ Pclass + Sex + Age +
                           Fare + Embarked + Fsize,
                         data = clean_train_data)

# Show model error
plot(rf_model, ylim=c(0,0.36))
legend('topright', colnames(rf_model$err.rate), col=1:3, fill=1:3)

```

La línea negra muestra la tasa de error general que cae por debajo del 20%. Las líneas rojas y verdes muestran la tasa de error de “muerto” y “sobrevivió” respectivamente. Con alrededor del 10%, nuestro modelo parece ser bueno para predecir mejor la muerte que la supervivencia.

A continuación, se comprobara la importancia de la variable relativa al explorar la disminución media en Gini calculada en todos los árboles.

```{r}
#Get importance
importance <- importance(rf_model)
varImportance <- data.frame(Variables = row.names(importance),
                            Importance = round(importance[ ,'MeanDecreaseGini'],2))

# Create a rank variable based on importance
rankImportance <- varImportance %>%
  mutate(Rank = paste0('#',dense_rank(desc(Importance))))

# Use ggplot2 to visualize the relative importance of variables
ggplot(rankImportance, aes(x = reorder(Variables, Importance),
                           y = Importance, fill = Importance)) +
  geom_bar(stat='identity') +
  geom_text(aes(x = Variables, y = 0.5, label = Rank),
            hjust=0, vjust=0.55, size = 4, colour = 'red') +
  labs(x = 'Variables') +
  coord_flip() +
  theme_few()
```

En la gráfica anterior se observa que la variables Fare se considera la más importantes. Esto contradice al método de regresión logística que las consideraba no significativas. Por otra parte, la variable SibSp está clasificada en séptimo lugar; mientras en la regresión logística era estadísticamente significativa. Sin embargo, la variable Fsize clasifica mejor que las variables SibSp y Parch. Esto tiene sentido ya que Fsize es la discretización de la combinación de estas dos variables.

******
# Representacó de los resultados a partir de tablas y gráficas
******

Este apartado se ha ido desarrollando a lo largo de esta práctica en apartados anteriores, mediante diagramas de barras, boxplots, tablas, ...


******
# Resolución del problema
******

En este trabajo se trató de la problemática de determinar qué variables influyeron más sobre la supervivencia de los pasajeros a bordo del Titanic. Para llevar a cabo esta tarea se realizó se utilizó el conjunto de datos de entrenamiento y conjunto de datos de prueba.

Sobre este conjunto de datos se realizó una fase de preprocesamiento que incluye varias tareas de limpieza de datos, (tales como, conversiones, eliminación los valores perdidos o nulos), discretización de valores numéricos, etc. En la imputación de valores perdidos se pueden destacar el trabajo realizado en la variable Edad (Age). Para la imputación de los valores perdidos de la característica edad (Age) se empleó el algoritmo KNN (K-Nearest Neighbour Imputation) de R. Se realizaron pruebas estadísticas para comprobar las dependencias entre Supervivencia y otras variables categóricas del conjunto de datos. Se identifico que existen evidencias estadísticas de dependencias entre la Supervivencia y las variables categóricas: Sexo (Sex), Clase (Pclass) y Tamaño de la familia (Fsize).


******
# Recursos
******

El desarrollo de la práctica se fundamenta con el material didáctico visto durante el curso:

*  Calvo M., Subirats L., Pérez D. (2019). Introducción a la limpieza y análisis de los datos. Editorial UOC.
*  Megan Squire (2015). Clean Data. Packt Publishing Ltd
*  Ramos Lorenzo, C. (2019). RPubs - Logistic Regressión. https://rpubs.com/MrCristianrl/500969

El conjunto de datos utilizado está publicado en el repositorio Kaggle y accesible a través de la siguiente url:

* [Titanic: Machine Learning from Disaster.](https://www.kaggle.com/c/titanic "Titanic Dataset")

